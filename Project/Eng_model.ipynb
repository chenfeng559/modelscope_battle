{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda_env\\Modelscope_GPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.33.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    " \n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_cpu_mem_usage=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens. With some proper optimization, we can achieve this within a span of \"just\" 90 days using 16 A100-40G GPUs üöÄüöÄ. The training has started on 2023-09-01.\n",
      "https://medium.com/the_tinylamasourceblog/how-to-use-aiocorepythonpipelinesforpretrainingaicompletebertolabrnnmlbearerweightsandmodels-785fbfeeefeddcfbcdeadacdfafcddcdcbcaffccdcba <filename>README.md<gh_stars>(C) Copyright [Knuthsoft](http:/www.knucklingtonsoftware).net), All rights reserved.<br/>[Source Code : https:github]()\n",
      "## KNOWLEDGE OF THIS PROJECT **** \n",
      "# Introduction #\n",
      "This repository contains all the code that I used in my thesis.\n",
      "It was created for myself because i am not very good programmer but it is useful when you are working with other software (like java or python) and want learn how something works like an object orient system which have multiple interfaces(such as database, file storage systems etc.). This repository should be considered mostly as learning material while doing your work without programming knowledge so if there will be any questions just ask me!   \n",
      "For those who do need help please use these links!    \n",
      "* git clone http://gitlab.org//kneevel/code repo link                     \t        ----->\n",
      "![ScreenShot][image-source]     |       ---->              ~~~~           |          +------ -->   <!---->         _________________----------------______|________>>--- >>*******************************.txt <<*****/ >--------> /=====  __\\|\\_\\ \\_\\\\\\/.'\\\" '`/\\'\\\\| \\\\ \\'_`' `'`''`````            |             ^^^^                ||               \\ \\ |\\ )^\\ \\| --.-._`-_.'-.. '-¬¥¬Ø‚Ä¢¬™¬°¬≠¬¨¬∏‚Äû¬∞¬®ÔøΩ¬ø¬Ω¬∫¬∑¬æ¬©¬≤¬Æ\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import transformers \n",
    "import torch\n",
    "model = \"PY007/TinyLlama-1.1B-step-50K-105b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "sequences = pipeline(\n",
    "    'who are you?',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=1.5,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=500,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: who are you?\n",
      "I've been playing with this idea of creating a new space to create community for myself and other artists that I love. It has always seemed more like what my own studio does than anything else, so I thought it would be good as well just have the opportunity at some point in time to put together an exhibition where we can share our work or show each others works without feeling too invasive by people wanting their stuff back outright from inside your studios. And also hopefully provide something fun along the way! The goal is not necessarily having exhibitions but being able to hang out outside after shows on occasion - if there aren't enough spaces around here then we could use one anyway :) This will happen pretty frequently though because every once-in-awhile someone might come up with ideas which they think make things really cool and want us all to try them before putting any real effort into making them ourselves... That happens quite often when everyone comes up with different combinations of materials (and how much energy those various experiments actually take). So basically anyone interested should get involved regardless: either help spread the word about yourself/your projects, ask questions, etc., send me feedback, offer suggestions & opinions / criticism... whatever helps move forward creatively while maintaining balance between working fulltime jobs, getting married, moving house, raising kids.. whatever makes sense. If nothing goes right please keep trying until succeeds :D Thanks again!! üëç <3 #artfarm @michaelkorsstudio\n",
      "@MKArtFarmer_UK What do u guys usually wear to art fairs?: Pants, Tanktop,Tshirt, Leisurely Dress | Fashion accessories | Bags & Accessory| Shoes|Skirts&Shorts\n",
      "This was done last August during MKExchange, Glasgow. For info see https://www.instagram.com/@milanakorbierobotikuk/ Q: How to change default theme in android app i am building application using flutter. In main view page user need custom layout style.In build method its already set color and font name..but now problem arises that same code must applied only for specific activity.how can override these settings.like say first screen has white text instead of black background?or second screen has blue color.what shall approach in design.\n",
      "i tried few methods  1) setting window\n"
     ]
    }
   ],
   "source": [
    "sequences = pipeline(\n",
    "    'who are you?',\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    repetition_penalty=1.5,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    max_length=500,\n",
    ")\n",
    "for seq in sequences:\n",
    "    print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.tencent.com/pypi/simple\n",
      "Collecting accelerate\n",
      "  Downloading https://mirrors.cloud.tencent.com/pypi/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/258.1 kB ? eta -:--:--\n",
      "     ------------ -------------------------- 81.9/258.1 kB 4.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ---- 225.3/258.1 kB 2.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- 258.1/258.1 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from accelerate) (1.11.0+cu113)\n",
      "Requirement already satisfied: huggingface-hub in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from accelerate) (0.17.2)\n",
      "Requirement already satisfied: typing-extensions in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: filelock in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from huggingface-hub->accelerate) (3.12.4)\n",
      "Requirement already satisfied: fsspec in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from huggingface-hub->accelerate) (2023.9.1)\n",
      "Requirement already satisfied: requests in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: colorama in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\conda_env\\modelscope_gpu\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E483063610>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /pypi/simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E483063910>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /pypi/simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E483063AC0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /pypi/simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001E483063C70>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /pypi/simple/accelerate/\n"
     ]
    }
   ],
   "source": [
    "pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda_env\\Modelscope_GPU\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:  1.11.0+cu113\n",
      "CUDA available:  True\n",
      "CUDA version:  11.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA version: \", torch.version.cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
