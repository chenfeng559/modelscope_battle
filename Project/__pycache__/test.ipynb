{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 22:55:16,791 - modelscope - INFO - Use user-specified model revision: v1.0.1\n",
      "2023-09-16 22:55:18,161 - modelscope - INFO - initiate model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer_asr-en-16k-vocab4199-pytorch\n",
      "2023-09-16 22:55:18,162 - modelscope - INFO - initiate model from location C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer_asr-en-16k-vocab4199-pytorch.\n",
      "2023-09-16 22:55:18,166 - modelscope - INFO - initialize model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer_asr-en-16k-vocab4199-pytorch\n",
      "2023-09-16 22:55:18,174 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-09-16 22:55:18,175 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-16 22:55:18,176 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\MSI-NB\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_paraformer_asr-en-16k-vocab4199-pytorch'}. trying to build by task and model information.\n",
      "2023-09-16 22:55:18,176 - modelscope - WARNING - No preprocessor key ('generic-asr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-09-16 22:55:24,768 - modelscope - INFO - Decoding with wav files ...\n",
      "2023-09-16 22:55:24,893 - modelscope - INFO - Computing the result of ASR ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'he tried to think how it could be'}\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import torch\n",
    "torch.cuda.is_available()\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='damo/speech_paraformer_asr-en-16k-vocab4199-pytorch',\n",
    "    model_revision=\"v1.0.1\")\n",
    "\n",
    "rec_result = inference_pipeline(audio_in='https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav')\n",
    "print(rec_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 23:06:36,120 - modelscope - INFO - Use user-specified model revision: v1.0.1\n",
      "2023-09-16 23:06:37,180 - modelscope - INFO - initiate model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer_asr-en-16k-vocab4199-pytorch\n",
      "2023-09-16 23:06:37,180 - modelscope - INFO - initiate model from location C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer_asr-en-16k-vocab4199-pytorch.\n",
      "2023-09-16 23:06:37,185 - modelscope - INFO - initialize model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer_asr-en-16k-vocab4199-pytorch\n",
      "2023-09-16 23:06:37,195 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-09-16 23:06:37,197 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-16 23:06:37,198 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\MSI-NB\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_paraformer_asr-en-16k-vocab4199-pytorch'}. trying to build by task and model information.\n",
      "2023-09-16 23:06:37,198 - modelscope - WARNING - No preprocessor key ('generic-asr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-09-16 23:06:44,177 - modelscope - INFO - Decoding with wav files ...\n",
      "2023-09-16 23:06:44,304 - modelscope - INFO - Computing the result of ASR ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'he tried to think how it could be'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Paraformer import *\n",
    "audio_to_text('https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_en.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchaudio' has no attribute 'Cheetah'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\code\\口语\\test.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m duration \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m         \u001b[39m# 录制持续时间（秒）\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# 初始化音频录制对象\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m recorder \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39;49mCheetah(sample_rate\u001b[39m=\u001b[39msample_rate, num_channels\u001b[39m=\u001b[39mnum_channels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# 开始录制音频\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m开始录制音频...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchaudio' has no attribute 'Cheetah'"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# 设置音频录制参数\n",
    "sample_rate = 44100  # 采样率，通常为44100 Hz\n",
    "num_channels = 1     # 声道数，通常为单声道\n",
    "duration = 5         # 录制持续时间（秒）\n",
    "\n",
    "# 初始化音频录制对象\n",
    "recorder = torchaudio.Cheetah(sample_rate=sample_rate, num_channels=num_channels)\n",
    "\n",
    "# 开始录制音频\n",
    "print(\"开始录制音频...\")\n",
    "audio_data, _ = recorder.record(duration)\n",
    "\n",
    "# 停止录制\n",
    "recorder.stop()\n",
    "\n",
    "# 将录制的音频数据保存到文件\n",
    "torchaudio.save(\"recorded_audio.wav\", audio_data, sample_rate)\n",
    "\n",
    "# 打印录制的音频信息\n",
    "print(f\"录制完成，采样率: {sample_rate}, 音频数据形状: {audio_data.shape}\")\n",
    "\n",
    "# 可选：播放录制的音频\n",
    "torchaudio.play(audio_data, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-19 20:40:42,602 - modelscope - INFO - PyTorch version 2.0.1+cu117 Found.\n",
      "2023-09-19 20:40:42,609 - modelscope - INFO - Loading ast index from C:\\Users\\MSI-NB\\.cache\\modelscope\\ast_indexer\n",
      "2023-09-19 20:40:42,802 - modelscope - INFO - Loading done! Current index file version is 1.9.1, with md5 d9280da6ec4fe78d3631deef47c44668 and a total number of 924 components indexed\n",
      "2023-09-19 20:40:45,316 - modelscope - INFO - Use user-specified model revision: v1.0.1\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: http://www.modelscope.cn/api/v1/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/repo/files?Revision=v1.0.1&Recursive=True (Caused by ResponseError('too many 500 error responses'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\connectionpool.py:889\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    888\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRetry: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url)\n\u001b[1;32m--> 889\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    890\u001b[0m         method,\n\u001b[0;32m    891\u001b[0m         url,\n\u001b[0;32m    892\u001b[0m         body,\n\u001b[0;32m    893\u001b[0m         headers,\n\u001b[0;32m    894\u001b[0m         retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    895\u001b[0m         redirect\u001b[39m=\u001b[39;49mredirect,\n\u001b[0;32m    896\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49massert_same_host,\n\u001b[0;32m    897\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    898\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[0;32m    899\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[0;32m    900\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    901\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[0;32m    902\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[0;32m    903\u001b[0m     )\n\u001b[0;32m    905\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\connectionpool.py:889\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    888\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRetry: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url)\n\u001b[1;32m--> 889\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    890\u001b[0m         method,\n\u001b[0;32m    891\u001b[0m         url,\n\u001b[0;32m    892\u001b[0m         body,\n\u001b[0;32m    893\u001b[0m         headers,\n\u001b[0;32m    894\u001b[0m         retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    895\u001b[0m         redirect\u001b[39m=\u001b[39;49mredirect,\n\u001b[0;32m    896\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49massert_same_host,\n\u001b[0;32m    897\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    898\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[0;32m    899\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[0;32m    900\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    901\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[0;32m    902\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[0;32m    903\u001b[0m     )\n\u001b[0;32m    905\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\connectionpool.py:879\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m     retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(method, url, response\u001b[39m=\u001b[39;49mresponse, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError:\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: http://www.modelscope.cn/api/v1/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/repo/files?Revision=v1.0.1&Recursive=True (Caused by ResponseError('too many 500 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\code\\口语\\test.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgr\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mParaformer\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[1;32mf:\\code\\口语\\Paraformer.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodelscope\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m Tasks\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m inference_pipeline \u001b[39m=\u001b[39m pipeline(\n\u001b[0;32m      6\u001b[0m     task\u001b[39m=\u001b[39;49mTasks\u001b[39m.\u001b[39;49mauto_speech_recognition,\n\u001b[0;32m      7\u001b[0m     \u001b[39m# model='damo/speech_paraformer_asr-en-16k-vocab4199-pytorch', # 英文版本\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdamo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m     model_revision\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mv1.0.1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maudio_to_text\u001b[39m(audio_wav_path):\n\u001b[0;32m     12\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m    Params: [wav_path]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    return: Text\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\builder.py:115\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, preprocessor, config_file, pipeline_name, framework, device, model_revision, ignore_file_pattern, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mif\u001b[39;00m third_party \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(ThirdParty\u001b[39m.\u001b[39mKEY)\n\u001b[1;32m--> 115\u001b[0m model \u001b[39m=\u001b[39m normalize_model_input(\n\u001b[0;32m    116\u001b[0m     model,\n\u001b[0;32m    117\u001b[0m     model_revision,\n\u001b[0;32m    118\u001b[0m     third_party\u001b[39m=\u001b[39;49mthird_party,\n\u001b[0;32m    119\u001b[0m     ignore_file_pattern\u001b[39m=\u001b[39;49mignore_file_pattern)\n\u001b[0;32m    120\u001b[0m pipeline_props \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: pipeline_name}\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m pipeline_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     \u001b[39m# get default pipeline for this task\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\builder.py:36\u001b[0m, in \u001b[0;36mnormalize_model_input\u001b[1;34m(model, model_revision, third_party, ignore_file_pattern)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[39mif\u001b[39;00m third_party \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m             user_agent[ThirdParty\u001b[39m.\u001b[39mKEY] \u001b[39m=\u001b[39m third_party\n\u001b[1;32m---> 36\u001b[0m         model \u001b[39m=\u001b[39m snapshot_download(\n\u001b[0;32m     37\u001b[0m             model,\n\u001b[0;32m     38\u001b[0m             revision\u001b[39m=\u001b[39;49mmodel_revision,\n\u001b[0;32m     39\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m     40\u001b[0m             ignore_file_pattern\u001b[39m=\u001b[39;49mignore_file_pattern)\n\u001b[0;32m     41\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(model)):\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\hub\\snapshot_download.py:105\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(model_id, revision, cache_dir, user_agent, local_files_only, cookies, ignore_file_pattern)\u001b[0m\n\u001b[0;32m     96\u001b[0m revision \u001b[39m=\u001b[39m _api\u001b[39m.\u001b[39mget_valid_revision(\n\u001b[0;32m     97\u001b[0m     model_id, revision\u001b[39m=\u001b[39mrevision, cookies\u001b[39m=\u001b[39mcookies)\n\u001b[0;32m     99\u001b[0m snapshot_header \u001b[39m=\u001b[39m headers \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCI_TEST\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron \u001b[39melse\u001b[39;00m {\n\u001b[0;32m    100\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mheaders,\n\u001b[0;32m    101\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\n\u001b[0;32m    102\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mSnapshot\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    103\u001b[0m     }\n\u001b[0;32m    104\u001b[0m }\n\u001b[1;32m--> 105\u001b[0m model_files \u001b[39m=\u001b[39m _api\u001b[39m.\u001b[39;49mget_model_files(\n\u001b[0;32m    106\u001b[0m     model_id\u001b[39m=\u001b[39;49mmodel_id,\n\u001b[0;32m    107\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    108\u001b[0m     recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    109\u001b[0m     use_cookies\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m cookies \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m cookies,\n\u001b[0;32m    110\u001b[0m     headers\u001b[39m=\u001b[39;49msnapshot_header,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    113\u001b[0m \u001b[39mif\u001b[39;00m ignore_file_pattern \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     ignore_file_pattern \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\hub\\api.py:549\u001b[0m, in \u001b[0;36mHubApi.get_model_files\u001b[1;34m(self, model_id, revision, root, recursive, use_cookies, headers)\u001b[0m\n\u001b[0;32m    547\u001b[0m     path \u001b[39m=\u001b[39m path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m&Root=\u001b[39m\u001b[39m{\u001b[39;00mroot\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    548\u001b[0m headers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders \u001b[39mif\u001b[39;00m headers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m headers\n\u001b[1;32m--> 549\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mget(\n\u001b[0;32m    550\u001b[0m     path, cookies\u001b[39m=\u001b[39;49mcookies, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    552\u001b[0m handle_http_response(r, logger, cookies, model_id)\n\u001b[0;32m    553\u001b[0m d \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\adapters.py:510\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ResponseError):\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mraise\u001b[39;00m RetryError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _ProxyError):\n\u001b[0;32m    513\u001b[0m     \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: http://www.modelscope.cn/api/v1/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/repo/files?Revision=v1.0.1&Recursive=True (Caused by ResponseError('too many 500 error responses'))"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from Paraformer import *\n",
    "import time\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "AudioSegment.converter = './ffmpeg-2023-09-07-git-9c9f48e7f2-essentials_build/bin/ffmpeg.exe'\n",
    "AudioSegment.ffmpeg = './ffmpeg-2023-09-07-git-9c9f48e7f2-essentials_build/bin/ffmpeg.exe'\n",
    "AudioSegment.ffprobe = './ffmpeg-2023-09-07-git-9c9f48e7f2-essentials_build/bin/ffprobe.exe'\n",
    "os.environ['no_proxy'] = 'localhost,127.0.0.1,::1'\n",
    "\n",
    "def generateText(audio):\n",
    "    # Paraformer读入音频并生成文本\n",
    "    res = audio_to_text(audio)\n",
    "    return res['text']\n",
    "\n",
    "app = gr.Interface(\n",
    "    fn=generateText,\n",
    "    # inputs='microphone',\n",
    "    inputs=gr.inputs.Audio(source=\"microphone\", type=\"filepath\", label=\"Input\"),\n",
    "    outputs=gr.outputs.Textbox(label='outputs'),\n",
    "    title='Paraformer语音转文本',\n",
    "    share=True\n",
    ")\n",
    "\n",
    "app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 20:49:11,484 - modelscope - INFO - Model revision not specified, use the latest revision: v1.2.1\n",
      "Downloading: 100%|██████████| 10.9k/10.9k [00:00<00:00, 1.60MB/s]\n",
      "Downloading: 100%|██████████| 173k/173k [00:00<00:00, 1.21MB/s]\n",
      "Downloading: 100%|██████████| 55.3k/55.3k [00:00<00:00, 581kB/s]\n",
      "Downloading: 100%|██████████| 628/628 [00:00<00:00, 88.7kB/s]\n",
      "Downloading: 100%|██████████| 91.0/91.0 [00:00<00:00, 18.1kB/s]\n",
      "Downloading: 100%|██████████| 725/725 [00:00<00:00, 121kB/s]\n",
      "Downloading: 100%|██████████| 226M/226M [01:55<00:00, 2.06MB/s] \n",
      "Downloading: 100%|██████████| 53.1k/53.1k [00:00<00:00, 579kB/s]\n",
      "Downloading: 100%|█████████▉| 840M/840M [07:13<00:00, 2.03MB/s]\n",
      "Downloading: 100%|██████████| 32.4k/32.4k [00:00<00:00, 672kB/s]\n",
      "Downloading: 100%|██████████| 7.90M/7.90M [00:03<00:00, 2.41MB/s]\n",
      "Downloading: 100%|██████████| 48.7k/48.7k [00:00<00:00, 473kB/s]\n",
      "Downloading: 100%|██████████| 34.0k/34.0k [00:00<00:00, 689kB/s]\n",
      "2023-09-19 20:58:29,006 - modelscope - INFO - initiate model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-09-19 20:58:29,007 - modelscope - INFO - initiate model from location C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch.\n",
      "2023-09-19 20:58:29,011 - modelscope - INFO - initialize model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\n",
      "2023-09-19 20:58:29,024 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-09-19 20:58:29,025 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-09-19 20:58:29,026 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'C:\\\\Users\\\\MSI-NB\\\\.cache\\\\modelscope\\\\hub\\\\damo\\\\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch'}. trying to build by task and model information.\n",
      "2023-09-19 20:58:29,027 - modelscope - WARNING - No preprocessor key ('generic-asr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "import torch\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    # model='damo/speech_paraformer_asr-en-16k-vocab4199-pytorch', # 英文版本\n",
    "    model='damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch',\n",
    "    # model_revision=\"v1.0.1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 20:41:57,630 - modelscope - INFO - Use user-specified model revision: v1.0.1\n"
     ]
    },
    {
     "ename": "RetryError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: http://www.modelscope.cn/api/v1/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/repo/files?Revision=v1.0.1&Recursive=True (Caused by ResponseError('too many 500 error responses'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\connectionpool.py:889\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    888\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRetry: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url)\n\u001b[1;32m--> 889\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    890\u001b[0m         method,\n\u001b[0;32m    891\u001b[0m         url,\n\u001b[0;32m    892\u001b[0m         body,\n\u001b[0;32m    893\u001b[0m         headers,\n\u001b[0;32m    894\u001b[0m         retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    895\u001b[0m         redirect\u001b[39m=\u001b[39;49mredirect,\n\u001b[0;32m    896\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49massert_same_host,\n\u001b[0;32m    897\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    898\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[0;32m    899\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[0;32m    900\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    901\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[0;32m    902\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[0;32m    903\u001b[0m     )\n\u001b[0;32m    905\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\connectionpool.py:889\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    888\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRetry: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, url)\n\u001b[1;32m--> 889\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    890\u001b[0m         method,\n\u001b[0;32m    891\u001b[0m         url,\n\u001b[0;32m    892\u001b[0m         body,\n\u001b[0;32m    893\u001b[0m         headers,\n\u001b[0;32m    894\u001b[0m         retries\u001b[39m=\u001b[39;49mretries,\n\u001b[0;32m    895\u001b[0m         redirect\u001b[39m=\u001b[39;49mredirect,\n\u001b[0;32m    896\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49massert_same_host,\n\u001b[0;32m    897\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    898\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[0;32m    899\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[0;32m    900\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    901\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[0;32m    902\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[0;32m    903\u001b[0m     )\n\u001b[0;32m    905\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\connectionpool.py:879\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m     retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(method, url, response\u001b[39m=\u001b[39;49mresponse, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError:\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: http://www.modelscope.cn/api/v1/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/repo/files?Revision=v1.0.1&Recursive=True (Caused by ResponseError('too many 500 error responses'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\code\\口语\\test.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mDemo\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m demo()\n",
      "File \u001b[1;32mf:\\code\\口语\\Demo.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgr\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mParaformer\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "File \u001b[1;32mf:\\code\\口语\\Paraformer.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodelscope\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m Tasks\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m inference_pipeline \u001b[39m=\u001b[39m pipeline(\n\u001b[0;32m      6\u001b[0m     task\u001b[39m=\u001b[39;49mTasks\u001b[39m.\u001b[39;49mauto_speech_recognition,\n\u001b[0;32m      7\u001b[0m     \u001b[39m# model='damo/speech_paraformer_asr-en-16k-vocab4199-pytorch', # 英文版本\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdamo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m     model_revision\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mv1.0.1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maudio_to_text\u001b[39m(audio_wav_path):\n\u001b[0;32m     12\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m    Params: [wav_path]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m    return: Text\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\builder.py:115\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, preprocessor, config_file, pipeline_name, framework, device, model_revision, ignore_file_pattern, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mif\u001b[39;00m third_party \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(ThirdParty\u001b[39m.\u001b[39mKEY)\n\u001b[1;32m--> 115\u001b[0m model \u001b[39m=\u001b[39m normalize_model_input(\n\u001b[0;32m    116\u001b[0m     model,\n\u001b[0;32m    117\u001b[0m     model_revision,\n\u001b[0;32m    118\u001b[0m     third_party\u001b[39m=\u001b[39;49mthird_party,\n\u001b[0;32m    119\u001b[0m     ignore_file_pattern\u001b[39m=\u001b[39;49mignore_file_pattern)\n\u001b[0;32m    120\u001b[0m pipeline_props \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: pipeline_name}\n\u001b[0;32m    121\u001b[0m \u001b[39mif\u001b[39;00m pipeline_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     \u001b[39m# get default pipeline for this task\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\builder.py:36\u001b[0m, in \u001b[0;36mnormalize_model_input\u001b[1;34m(model, model_revision, third_party, ignore_file_pattern)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[39mif\u001b[39;00m third_party \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m             user_agent[ThirdParty\u001b[39m.\u001b[39mKEY] \u001b[39m=\u001b[39m third_party\n\u001b[1;32m---> 36\u001b[0m         model \u001b[39m=\u001b[39m snapshot_download(\n\u001b[0;32m     37\u001b[0m             model,\n\u001b[0;32m     38\u001b[0m             revision\u001b[39m=\u001b[39;49mmodel_revision,\n\u001b[0;32m     39\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m     40\u001b[0m             ignore_file_pattern\u001b[39m=\u001b[39;49mignore_file_pattern)\n\u001b[0;32m     41\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mlist\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(model[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n\u001b[0;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(model)):\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\hub\\snapshot_download.py:105\u001b[0m, in \u001b[0;36msnapshot_download\u001b[1;34m(model_id, revision, cache_dir, user_agent, local_files_only, cookies, ignore_file_pattern)\u001b[0m\n\u001b[0;32m     96\u001b[0m revision \u001b[39m=\u001b[39m _api\u001b[39m.\u001b[39mget_valid_revision(\n\u001b[0;32m     97\u001b[0m     model_id, revision\u001b[39m=\u001b[39mrevision, cookies\u001b[39m=\u001b[39mcookies)\n\u001b[0;32m     99\u001b[0m snapshot_header \u001b[39m=\u001b[39m headers \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCI_TEST\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron \u001b[39melse\u001b[39;00m {\n\u001b[0;32m    100\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mheaders,\n\u001b[0;32m    101\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\n\u001b[0;32m    102\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mSnapshot\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    103\u001b[0m     }\n\u001b[0;32m    104\u001b[0m }\n\u001b[1;32m--> 105\u001b[0m model_files \u001b[39m=\u001b[39m _api\u001b[39m.\u001b[39;49mget_model_files(\n\u001b[0;32m    106\u001b[0m     model_id\u001b[39m=\u001b[39;49mmodel_id,\n\u001b[0;32m    107\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    108\u001b[0m     recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    109\u001b[0m     use_cookies\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m cookies \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m cookies,\n\u001b[0;32m    110\u001b[0m     headers\u001b[39m=\u001b[39;49msnapshot_header,\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    113\u001b[0m \u001b[39mif\u001b[39;00m ignore_file_pattern \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m     ignore_file_pattern \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\hub\\api.py:549\u001b[0m, in \u001b[0;36mHubApi.get_model_files\u001b[1;34m(self, model_id, revision, root, recursive, use_cookies, headers)\u001b[0m\n\u001b[0;32m    547\u001b[0m     path \u001b[39m=\u001b[39m path \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m&Root=\u001b[39m\u001b[39m{\u001b[39;00mroot\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    548\u001b[0m headers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheaders \u001b[39mif\u001b[39;00m headers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m headers\n\u001b[1;32m--> 549\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mget(\n\u001b[0;32m    550\u001b[0m     path, cookies\u001b[39m=\u001b[39;49mcookies, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    552\u001b[0m handle_http_response(r, logger, cookies, model_id)\n\u001b[0;32m    553\u001b[0m d \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m \n\u001b[0;32m    596\u001b[0m \u001b[39m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \u001b[39m:rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m kwargs\u001b[39m.\u001b[39msetdefault(\u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 602\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\requests\\adapters.py:510\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectTimeout(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, ResponseError):\n\u001b[1;32m--> 510\u001b[0m     \u001b[39mraise\u001b[39;00m RetryError(e, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(e\u001b[39m.\u001b[39mreason, _ProxyError):\n\u001b[0;32m    513\u001b[0m     \u001b[39mraise\u001b[39;00m ProxyError(e, request\u001b[39m=\u001b[39mrequest)\n",
      "\u001b[1;31mRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8001): Max retries exceeded with url: http://www.modelscope.cn/api/v1/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/repo/files?Revision=v1.0.1&Recursive=True (Caused by ResponseError('too many 500 error responses'))"
     ]
    }
   ],
   "source": [
    "from Demo import *\n",
    "demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching examples at: 'f:\\code\\口语\\gradio_cached_examples\\16'\n",
      "Caching example 1/3\n",
      "Caching example 2/3\n",
      "Caching example 3/3\n",
      "Caching complete\n",
      "\n",
      "Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\code\\口语\\test.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAsk me anything!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m gr\u001b[39m.\u001b[39;49mChatInterface(\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     yes_man,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     chatbot\u001b[39m=\u001b[39;49mgr\u001b[39m.\u001b[39;49mChatbot(height\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     textbox\u001b[39m=\u001b[39;49mgr\u001b[39m.\u001b[39;49mTextbox(placeholder\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAsk me a yes or no question\u001b[39;49m\u001b[39m\"\u001b[39;49m, container\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, scale\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     title\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mYes Man\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mAsk Yes Man any question\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     theme\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msoft\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     examples\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mHello\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mAm I cool?\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mAre tomatoes vegetables?\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     cache_examples\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     retry_btn\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     undo_btn\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mDelete Previous\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     clear_btn\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mClear\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m )\u001b[39m.\u001b[39;49mlaunch()\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\gradio\\blocks.py:1982\u001b[0m, in \u001b[0;36mBlocks.launch\u001b[1;34m(self, inline, inbrowser, share, debug, enable_queue, max_threads, auth, auth_message, prevent_thread_lock, show_error, server_name, server_port, show_tips, height, width, encrypt, favicon_path, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_verify, quiet, show_api, file_directories, allowed_paths, blocked_paths, root_path, _frontend, app_kwargs)\u001b[0m\n\u001b[0;32m   1974\u001b[0m \u001b[39m# If running in a colab or not able to access localhost,\u001b[39;00m\n\u001b[0;32m   1975\u001b[0m \u001b[39m# a shareable link must be created.\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1977\u001b[0m     _frontend\n\u001b[0;32m   1978\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m wasm_utils\u001b[39m.\u001b[39mIS_WASM\n\u001b[0;32m   1979\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m networking\u001b[39m.\u001b[39murl_ok(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlocal_url)\n\u001b[0;32m   1980\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshare\n\u001b[0;32m   1981\u001b[0m ):\n\u001b[1;32m-> 1982\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1983\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1984\u001b[0m     )\n\u001b[0;32m   1986\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_colab:\n\u001b[0;32m   1987\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m quiet:\n",
      "\u001b[1;31mValueError\u001b[0m: When localhost is not accessible, a shareable link must be created. Please set share=True or check your proxy settings to allow access to localhost."
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "os.environ['no_proxy'] = 'localhost,127.0.0.1,::1'\n",
    "def yes_man(message, history):\n",
    "    if message.endswith(\"?\"):\n",
    "        return \"Yes\"\n",
    "    else:\n",
    "        return \"Ask me anything!\"\n",
    "\n",
    "gr.ChatInterface(\n",
    "    yes_man,\n",
    "    chatbot=gr.Chatbot(height=300),\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me a yes or no question\", container=False, scale=7),\n",
    "    title=\"Yes Man\",\n",
    "    description=\"Ask Yes Man any question\",\n",
    "    theme=\"soft\",\n",
    "    examples=[\"Hello\", \"Am I cool?\", \"Are tomatoes vegetables?\"],\n",
    "    cache_examples=True,\n",
    "    retry_btn=None,\n",
    "    undo_btn=\"Delete Previous\",\n",
    "    clear_btn=\"Clear\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7890\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7890/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] dasd\n",
      "[['dasd', \"**That's cool!**\"]] dsadsadsad\n",
      "[['dasd', \"**That's cool!**\"], ['dsadsadsad', \"**That's cool!**\"]] shabi\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "import time\n",
    "from Paraformer import *\n",
    "os.environ['no_proxy'] = 'localhost,127.0.0.1,::1'\n",
    "\n",
    "front = {\n",
    "    'input_audio_path' : None, # 语音输入的wav文件路径\n",
    "    'audio_to_text' : None, # 通过Paraformer模型识别的文本\n",
    "    'output_chatbot_text' : None, # chatbot输出的文本\n",
    "    'output_chatbot_audio' : None, # chatbot输出的语音路径\n",
    "}\n",
    "\n",
    "def save_audio_path(audio_path):\n",
    "    # 保存麦克风输入的路径\n",
    "    global front\n",
    "    front['input_audio_path'] = audio_path\n",
    "\n",
    "def audio_to_llm(history, audio):\n",
    "    # paraformer语音识别\n",
    "    global front\n",
    "    text = generateAudioText(audio)\n",
    "    front['audio_to_text'] = text\n",
    "    history = history + [(text, None)]\n",
    "    return history\n",
    "\n",
    "def play_audio():\n",
    "    # 输出llm生成的文字语音\n",
    "    global front\n",
    "    # 转换成语音\n",
    "    audio = front['input_audio_path']\n",
    "    return audio\n",
    "\n",
    "def bot(history):\n",
    "    # 放入llm\n",
    "    input_text = history[-1][0]\n",
    "    response = \"**That's cool!**\" # 这个是llm的输出\n",
    "    history[-1][1] = \"\"\n",
    "    for character in response:\n",
    "        history[-1][1] += character\n",
    "        time.sleep(0.05)\n",
    "        yield history\n",
    "\n",
    "def add_text(history, text):\n",
    "    # 添加对话记录\n",
    "    history = history + [(text, None)]\n",
    "    return history, gr.update(value=\"\", interactive=False)\n",
    "\n",
    "\n",
    "def add_file(history, file):\n",
    "    history = history + [((file.name,), None)]\n",
    "    return history\n",
    "\n",
    "\n",
    "def Demo():\n",
    "    with gr.Blocks() as demo:\n",
    "        chatbot = gr.Chatbot(\n",
    "            [],\n",
    "            elem_id=\"chatbot\",\n",
    "            bubble_full_width=False,\n",
    "            # avatar_images=(None, (os.path.join(os.path.dirname(__file__), \"avatar.png\"))),\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            txt = gr.Textbox(\n",
    "                scale=4,\n",
    "                show_label=False,\n",
    "                placeholder=\"Enter text and press enter\",\n",
    "                container=False,\n",
    "            )\n",
    "            with gr.Blocks():\n",
    "                with gr.Row():\n",
    "                    microphone = gr.Audio(source=\"microphone\", type=\"filepath\", label=\"语音输入\", autoplay=False,)\n",
    "                    submitButton = gr.Button('语音输入')\n",
    "                with gr.Row():\n",
    "                    output_audio = gr.Audio(type='filepath', label='语音输出', interactive=False, autoplay=True)\n",
    "                    output_audio_button = gr.Button('语音输出')\n",
    "            # btn = gr.UploadButton(\"📁\", file_types=[\"image\", \"video\", \"audio\"])\n",
    "\n",
    "        # 存储麦克风临时路径\n",
    "        microphone.change(fn=save_audio_path, inputs=[microphone]) \n",
    "\n",
    "        # 语音输入\n",
    "        audio_msg = submitButton.click(fn=audio_to_llm, inputs=[chatbot, microphone], outputs=[chatbot], queue=False).then( \n",
    "                        fn=bot, inputs=chatbot, outputs=chatbot\n",
    "                    )\n",
    "\n",
    "        # 文本输入\n",
    "        txt_msg = txt.submit(add_text, [chatbot, txt], [chatbot, txt], queue=False).then(\n",
    "            fn=bot, inputs=chatbot, outputs=chatbot\n",
    "        )\n",
    "        txt_msg.then(lambda: gr.update(interactive=True), None, [txt], queue=False)\n",
    "\n",
    "        # 语音输出\n",
    "        output_msg = output_audio_button.click(fn=play_audio, inputs=[], outputs=[output_audio])\n",
    "\n",
    "        # file_msg = btn.upload(add_file, [chatbot, btn], [chatbot], queue=False).then(\n",
    "        #     bot, chatbot, chatbot\n",
    "        # )\n",
    "\n",
    "    demo.queue()\n",
    "    demo.launch(share=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_audio_path': 'C:\\\\Users\\\\MSI-NB\\\\AppData\\\\Local\\\\Temp\\\\gradio\\\\eac47fe50f0745ab2637b52c60ea637fe2f4cc79\\\\audio-0-100.wav',\n",
       " 'audio_to_text': None,\n",
       " 'output_chatbot_text': None,\n",
       " 'output_chatbot_audio': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_audio_path': None, 'audio_to_text': None}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DEFAULT_TEMP_DIR',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_deserialize_single',\n",
       " '_id',\n",
       " '_multiple_file_api_info',\n",
       " '_multiple_file_example_inputs',\n",
       " '_multiple_file_serialized_info',\n",
       " '_serialize_single',\n",
       " '_setup_stream',\n",
       " '_single_file_api_info',\n",
       " '_single_file_example_inputs',\n",
       " '_single_file_serialized_info',\n",
       " '_skip_init_processing',\n",
       " 'api_info',\n",
       " 'as_example',\n",
       " 'attach_load_event',\n",
       " 'audio_to_temp_file',\n",
       " 'autoplay',\n",
       " 'base64_to_temp_file_if_needed',\n",
       " 'change',\n",
       " 'check_streamable',\n",
       " 'clear',\n",
       " 'container',\n",
       " 'deserialize',\n",
       " 'download_temp_copy_if_needed',\n",
       " 'elem_classes',\n",
       " 'elem_id',\n",
       " 'end',\n",
       " 'example_inputs',\n",
       " 'file_bytes_to_file',\n",
       " 'format',\n",
       " 'get_block_name',\n",
       " 'get_config',\n",
       " 'get_expected_parent',\n",
       " 'get_interpretation_scores',\n",
       " 'get_load_fn_and_initial_value',\n",
       " 'get_masked_inputs',\n",
       " 'get_specific_update',\n",
       " 'hash_base64',\n",
       " 'hash_bytes',\n",
       " 'hash_file',\n",
       " 'hash_url',\n",
       " 'img_array_to_temp_file',\n",
       " 'info',\n",
       " 'input_api_info',\n",
       " 'interactive',\n",
       " 'interpretation_segments',\n",
       " 'is_rendered',\n",
       " 'label',\n",
       " 'load_event',\n",
       " 'load_event_to_attach',\n",
       " 'make_temp_copy_if_needed',\n",
       " 'min_width',\n",
       " 'output_api_info',\n",
       " 'parent',\n",
       " 'pause',\n",
       " 'pil_to_temp_file',\n",
       " 'play',\n",
       " 'postprocess',\n",
       " 'preprocess',\n",
       " 'render',\n",
       " 'root_url',\n",
       " 'save_uploaded_file',\n",
       " 'scale',\n",
       " 'serialize',\n",
       " 'serialized_info',\n",
       " 'set_event_trigger',\n",
       " 'set_interpret_parameters',\n",
       " 'share_token',\n",
       " 'show_download_button',\n",
       " 'show_edit_button',\n",
       " 'show_label',\n",
       " 'show_share_button',\n",
       " 'source',\n",
       " 'start_recording',\n",
       " 'stop',\n",
       " 'stop_recording',\n",
       " 'stream',\n",
       " 'stream_output',\n",
       " 'streaming',\n",
       " 'style',\n",
       " 'temp_files',\n",
       " 'tokenize',\n",
       " 'type',\n",
       " 'unrender',\n",
       " 'update',\n",
       " 'upload',\n",
       " 'value',\n",
       " 'visible']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(gr.Audio(source=\"microphone\", \n",
    "                                  type=\"filepath\", \n",
    "                                  label=\"语音输入\", \n",
    "                                  autoplay=False,\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7871\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7871/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(history, input):\n",
    "    return history + [(input, \"Hello, \" + input)]\n",
    "\n",
    "def vote(data: gr.LikeData):\n",
    "    if data.liked:\n",
    "        print(\"You upvoted this response: \" + data.value)\n",
    "    else:\n",
    "        print(\"You downvoted this response: \" + data.value)\n",
    "    \n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    textbox = gr.Textbox()\n",
    "    textbox.submit(greet, [chatbot, textbox], [chatbot])\n",
    "    chatbot.like(vote, None, None)  # Adding this line causes the like/dislike icons to appear in your chatbot\n",
    "    \n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 10:43:33,170 - modelscope - INFO - Model revision not specified, use the latest revision: v1.3.0\n",
      "Downloading: 100%|██████████| 422/422 [00:00<00:00, 69.6kB/s]\n",
      "Downloading: 100%|██████████| 1.57k/1.57k [00:00<00:00, 269kB/s]\n",
      "Downloading: 100%|██████████| 210k/210k [00:00<00:00, 1.03MB/s]\n",
      "Downloading: 100%|█████████▉| 2.45G/2.45G [24:32<00:00, 1.79MB/s]\n",
      "Downloading: 100%|██████████| 8.51k/8.51k [00:00<00:00, 1.25MB/s]\n",
      "Downloading: 100%|██████████| 1.60M/1.60M [00:00<00:00, 1.90MB/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DistributedGPT3Pipeline: Distributed package doesn't have NCCL built in",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\multiprocessing\\pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\nlp\\distributed_gpt3_pipeline.py\", line 44, in _instantiate_one\n    cls.model = DistributedGPT3(model_dir, rank, **kwargs)\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\models\\nlp\\gpt3\\distributed_gpt3.py\", line 959, in __init__\n    init_megatron_util(megatron_cfg, model_dir, rank=rank)\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\utils\\megatron_utils.py\", line 64, in init_megatron_util\n    initialize_megatron(megatron_cfg)\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\megatron_util\\initialize.py\", line 70, in initialize_megatron\n    finish_mpu_init()\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\megatron_util\\initialize.py\", line 51, in finish_mpu_init\n    _initialize_distributed(master_ip, master_port)\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\megatron_util\\initialize.py\", line 139, in _initialize_distributed\n    torch.distributed.init_process_group(\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 907, in init_process_group\n    default_pg = _new_process_group_helper(\n  File \"c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\torch\\distributed\\distributed_c10d.py\", line 1013, in _new_process_group_helper\n    raise RuntimeError(\"Distributed package doesn't have NCCL \" \"built in\")\nRuntimeError: Distributed package doesn't have NCCL built in\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\utils\\registry.py:212\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[1;34m(cfg, registry, group_key, default_args)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 212\u001b[0m         \u001b[39mreturn\u001b[39;00m obj_cls(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    214\u001b[0m     \u001b[39m# Normal TypeError does not print class name.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\nlp\\distributed_gpt3_pipeline.py:37\u001b[0m, in \u001b[0;36mDistributedGPT3Pipeline.__init__\u001b[1;34m(self, model, preprocessor, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     preprocessor \u001b[39m=\u001b[39m TextGenerationJiebaPreprocessor(model)\n\u001b[1;32m---> 37\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(model, preprocessor\u001b[39m=\u001b[39;49mpreprocessor, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     38\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mhasattr\u001b[39m(preprocessor, \u001b[39m'\u001b[39m\u001b[39mtokenizer\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\base.py:474\u001b[0m, in \u001b[0;36mDistributedPipeline.__init__\u001b[1;34m(self, model, preprocessor, auto_collate, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mMASTER_PORT\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs[\u001b[39m'\u001b[39m\u001b[39mmaster_port\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> 474\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_pool\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    475\u001b[0m     partial(\n\u001b[0;32m    476\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m_instantiate_one,\n\u001b[0;32m    477\u001b[0m         model_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_dir,\n\u001b[0;32m    478\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfg\u001b[39m.\u001b[39;49mmodel,\n\u001b[0;32m    479\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), ranks)\n\u001b[0;32m    480\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\multiprocessing\\pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[1;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[39mApply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[39min a list that is returned.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\multiprocessing\\pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 771\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Distributed package doesn't have NCCL built in",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mf:\\code\\口语\\test.ipynb Cell 13\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodelscope\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipelines\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodelscope\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconstant\u001b[39;00m \u001b[39mimport\u001b[39;00m Tasks\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text_generation_zh \u001b[39m=\u001b[39m pipeline(Tasks\u001b[39m.\u001b[39;49mtext_generation, model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdamo/nlp_gpt3_text-generation_1.3B\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m随着计算机视觉的飞速发展,人脸识别技术已从简单场景发展到复杂场景,也即姿态、光照、表情、噪声、遮挡、化妆、年龄、种族、性别等差异化所呈现的复杂场景。尽管已有的人脸识别系统在特定约束环境下的识别成功率较高,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/code/%E5%8F%A3%E8%AF%AD/test.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result_zh \u001b[39m=\u001b[39m text_generation_zh(text)\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\builder.py:159\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, preprocessor, config_file, pipeline_name, framework, device, model_revision, ignore_file_pattern, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     cfg\u001b[39m.\u001b[39mpreprocessor \u001b[39m=\u001b[39m preprocessor\n\u001b[1;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m build_pipeline(cfg, task_name\u001b[39m=\u001b[39;49mtask)\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\pipelines\\builder.py:65\u001b[0m, in \u001b[0;36mbuild_pipeline\u001b[1;34m(cfg, task_name, default_args)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_pipeline\u001b[39m(cfg: ConfigDict,\n\u001b[0;32m     55\u001b[0m                    task_name: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     56\u001b[0m                    default_args: \u001b[39mdict\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     57\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" build pipeline given model config dict.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m        default_args (dict, optional): Default initialization arguments.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m build_from_cfg(\n\u001b[0;32m     66\u001b[0m         cfg, PIPELINES, group_key\u001b[39m=\u001b[39;49mtask_name, default_args\u001b[39m=\u001b[39;49mdefault_args)\n",
      "File \u001b[1;32mc:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\modelscope\\utils\\registry.py:215\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[1;34m(cfg, registry, group_key, default_args)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[39mreturn\u001b[39;00m obj_cls(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39margs)\n\u001b[0;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    214\u001b[0m     \u001b[39m# Normal TypeError does not print class name.\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mobj_cls\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DistributedGPT3Pipeline: Distributed package doesn't have NCCL built in"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "text_generation_zh = pipeline(Tasks.text_generation, model='damo/nlp_gpt3_text-generation_1.3B')\n",
    "text = \"随着计算机视觉的飞速发展,人脸识别技术已从简单场景发展到复杂场景,也即姿态、光照、表情、噪声、遮挡、化妆、年龄、种族、性别等差异化所呈现的复杂场景。尽管已有的人脸识别系统在特定约束环境下的识别成功率较高,\"\n",
    "result_zh = text_generation_zh(text)\n",
    "print(result_zh['text'][len(text):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '随着计算机视觉的飞速发展,人脸识别技术已从简单场景发展到复杂场景,也即姿态、光照、表情、噪声、遮挡、化妆、年龄、种族、性别等差异化所呈现的复杂场景。尽管已有的人脸识别系统在特定约束环境下的识别成功率较高,但大多数面部识别技术仍存在一些发展缺陷。此外,人脸识别技术的复杂程度仍以相对常识水平为评价标准,并没有真正意义上的基于的认证,本文结合“人脸的认知”与“功能人脸识别”的分析与介绍,对人脸认知技术的复杂性问题进行了分析和论述。第一章简介人脸的认知第一'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "text_generation_zh = pipeline(Tasks.text_generation, model='damo/nlp_gpt3_kuakua-robot_chinese-large')\n",
    "result_zh = text_generation_zh(\"今天终于拿到驾照了，求夸 | \")\n",
    "print(result_zh['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
