{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ninja\n",
      "  Using cached ninja-1.11.1-py2.py3-none-win_amd64.whl (313 kB)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\msi-nb\\.conda\\envs\\llm_tutor\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\msi-nb\\.conda\\envs\\llm_tutor\\lib\\site-packages)\n",
      "  WARNING: The script ninja.exe is installed in 'c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Looking in links: https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html\n",
      "Requirement already satisfied: megatron_util in c:\\users\\msi-nb\\.conda\\envs\\llm_tutor\\lib\\site-packages (1.3.2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\msi-nb\\.conda\\envs\\llm_tutor\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\msi-nb\\.conda\\envs\\llm_tutor\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install megatron_util -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-20 11:02:45,983 - modelscope - INFO - PyTorch version 2.0.1+cu117 Found.\n",
      "2023-09-20 11:02:45,989 - modelscope - INFO - Loading ast index from C:\\Users\\MSI-NB\\.cache\\modelscope\\ast_indexer\n",
      "2023-09-20 11:02:46,349 - modelscope - INFO - Loading done! Current index file version is 1.9.1, with md5 d9280da6ec4fe78d3631deef47c44668 and a total number of 924 components indexed\n",
      "c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-20 11:02:48,322 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.1\n",
      "2023-09-20 11:02:50,816 - modelscope - INFO - initiate model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\nlp_gpt3_text-generation_chinese-base\n",
      "2023-09-20 11:02:50,817 - modelscope - INFO - initiate model from location C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\nlp_gpt3_text-generation_chinese-base.\n",
      "2023-09-20 11:02:50,823 - modelscope - INFO - initialize model from C:\\Users\\MSI-NB\\.cache\\modelscope\\hub\\damo\\nlp_gpt3_text-generation_chinese-base\n",
      "c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "c:\\Users\\MSI-NB\\.conda\\envs\\llm_tutor\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:377: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "text_generation_zh = pipeline(Tasks.text_generation, model='damo/nlp_gpt3_text-generation_chinese-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输出函数\n",
    "def LLM_text(input):\n",
    "    \n",
    "    result_zh = text_generation_zh(input)\n",
    "    return re.sub(input, '', result_zh['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "简介：在 2012 春夏季《英语娱乐周刊》举办的“世界级”节目中，特别邀请“中国青年”崔永元作“北京的太阳”回答观众的提问。网友评论“我说的都是实话！”“我们可以战略的视角去做事，如果我们不能战略地制定公司的战略，最终只会一无所有……”网友提问“的经历给了我什么价值”。网友回答“虚心的朋友会发现我的功劳我去学习！！！可以很骄傲地说，如果我对自己所做的每一个事情都感到满意，那我们就不会因为我说的一句话被人们误解了！“我认为，我们所有人的头脑中\n"
     ]
    }
   ],
   "source": [
    "print(LLM_text(\"夸夸我\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
